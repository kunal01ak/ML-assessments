import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Naive Bayes algorithm implementation
class NaiveBayes:
    def _init_(self):
        self.prior = None
        self.likelihood = None
    
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.prior = {}
        self.likelihood = {}
        
        # Calculate prior probabilities
        unique_classes, class_counts = np.unique(y, return_counts=True)
        for cls, count in zip(unique_classes, class_counts):
            self.prior[cls] = count / n_samples
        
        # Calculate likelihood probabilities
        for feature in range(n_features):
            self.likelihood[feature] = {}
            unique_feature_values = np.unique(X[:, feature])
            for cls in unique_classes:
                self.likelihood[feature][cls] = {}
                for value in unique_feature_values:
                    self.likelihood[feature][cls][value] = (
                        np.sum(X[y == cls][:, feature] == value) / class_counts[cls]
                    )
    
    def predict(self, X):
        n_samples, n_features = X.shape
        predictions = []
        
        for i in range(n_samples):
            posterior = {cls: np.log(self.prior[cls]) for cls in self.prior}
            for feature in range(n_features):
                for cls in posterior:
                    posterior[cls] += np.log(self.likelihood[feature][cls][X[i, feature]])
            
            predicted_class = max(posterior, key=posterior.get)
            predictions.append(predicted_class)
        
        return predictions
       
# Example usage of the implemented algorithms
# Assuming X_train and y_train are the feature and target arrays for training

# Naive Bayes
nb = NaiveBayes()
nb.fit(X_train, y_train)
nb_predictions = nb.predict(X_test)
